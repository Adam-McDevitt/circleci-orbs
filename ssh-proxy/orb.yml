version: 2.1
description: An orb using sshuttle to establish a proxy to a remote network for performing deployments
# Some of this Orb have been inspired by https://circleci.com/developer/orbs/orb/symbol/ssh-tunnel (MIT Licence)

commands:
  proxy-up:
    description: "Establish a routed sshuttle proxy over an SSH tunnel to the remote network"

    parameters:
      hostname:
        description: "The hostname of the SSH proxy server"
        type: string
      port:
        description: "The port of the SSH proxy server"
        type: integer
      username:
        description: "The username to connect to the SSH proxy server"
        type: string
      private_key_fingerprint:
        description: |
          The private key for connecting to the SSH proxy server. The key must be added via CircleCI settings 
          first: https://circleci.com/docs/2.0/add-ssh-key/
        type: string
      routed_network_cidrs:
        description: |
          A string of CIDR blocks requests for which should be proxied, separated by a space. For individual 
          IP addresses, use x.x.x.x/32 to represent them
        type: string
      connection_test_host:
        description: |
          The destination IP or hostname in the private network which we want to reach via the proxy, for 
          testing the connection
        type: string
      connection_test_port:
        description: |
          The port for the host in the private network which we want to reach via the proxy, for testing the 
          connection
        type: integer

    steps:
      - add_ssh_keys:
          fingerprints:
            - << parameters.private_key_fingerprint >>
      - run:
          name: Install additional packages required
          shell: /bin/bash
          command: |
            sudo apt update && sudo apt install -y sshuttle
      # We must run sshuttle with sudo permissions to set ip routes, but we also need pass
      # in SSH_AUTH_SOCK so that SSH agent is used to supply the private key added via CircleCI
      - run:
          name: Spin up sshuttle tunnel
          shell: /bin/bash
          background: true
          command: |
            sudo SSH_AUTH_SOCK="$SSH_AUTH_SOCK" \
              sshuttle -r << parameters.username >>@<< parameters.hostname >>:<< parameters.port >> \
              << parameters.routed_network_cidrs >> --python /usr/local/bin/python3 --dns
      - run: 
          name: Wait for tunnel establishment
          shell: /bin/bash
          command: |
            COUNT=0
            until timeout 2 nc -z << parameters.connection_test_host >> << parameters.connection_test_port >>;
            do
              if [ $COUNT -ge 10 ]; then
                echo "ssh tunnel set up timeout";
                exit 1;
              fi;
              ((COUNT++))
              sleep 1
            done

  proxy-down:
    steps:
      - run:
          name: Release all sshuttle sessions, which will kill forked ssh sessions as well
          command: sudo pkill sshuttle

  configure-gke-cluster-access:
    description: |
      If the remote network is the control plane of a GKE cluster, this command provides a 
      short-cut for reconfiguring kubeconfig to use the private control plane IP. AWS EKS
      clusters do not require this treatment as they use a VPC DNS-compatible hostname.

    parameters:
      cluster:
        description: "The name of the cluster to be connected to"
        type: string
      compute_zone:
        description: |
          The GCP zone for the cluster's control plane, if your cluster is regional 
          rather than zonal, simply set the value as the region name (e.g. europe-west1)
        type: string
      project_id:
        description: |
          The ID of the GCP project your cluster is in, note that this may be different
          from the human-readable name. Find both in the cloud console project list.
        type: string
    
    steps:
      - run:
          command: |
            gcloud container clusters get-credentials <<parameters.cluster>> \
              --project <<parameters.google-project-id>> \
              --zone <<parameters.google-compute-zone>> \
              --internal-ip
          name: Reconfigure kubeconfig to use private control plane IP

# This orb must be executed on a VM rather than container, as sshuttle needs to add ip routes
# Why is this necessary? We want TLS connections to work through the proxy without requiring
# any special configurations on the client itself -- such as SOCKS proxy settings -- and the
# easiest way to do this in an ephemeral environment is to tunnel DNS and specific remote IPs.
executors:
  default:
    machine:
      image: ubuntu-1604:202007-01
